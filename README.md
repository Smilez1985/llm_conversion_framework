# llm_conversion_framework 

Ein GUI-basiertes LLM Deployment Framework, das beliebige LLMs automatisiert optimieren & quantisieren kann. FÃ¼r jede CPU, GPU oder NPU perfekt optimiert. **MVP: RK3566 Support.**

# ğŸš€ LLM Cross-Compiler Framework

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![Docker](https://img.shields.io/badge/docker-20.10+-blue.svg)](https://docs.docker.com/get-docker/)
[![Poetry](https://img.shields.io/badge/poetry-1.5+-blue.svg)](https://python-poetry.org/)

**Professionelles modulares Framework fÃ¼r Cross-Compilation von Large Language Models auf Edge-Hardware**

Eliminiert die KomplexitÃ¤t der Cross-Kompilierung und Quantisierung von LLMs fÃ¼r fragmentierte Edge-Hardware (CPUs, GPUs, NPUs). Community-driven, Docker-basiert, production-ready.

---

**ğŸ› ï¸ Schluss mit Dependency-HÃ¶lle: Ein universelles Cross-Compiling Framework fÃ¼r ALLE KI-Hardware.**

Wir haben ein Problem gelÃ¶st, das jeder kennt, aber niemand angeht: Die saubere Kompilierung von LLMs und NPU-Tools fÃ¼r unterschiedliche Hardware-Architekturen.

Ich stelle vor: Das **LLM Cross-Compiler Framework**. Es ist keine einfache "Installations-Anleitung", sondern eine Docker-basierte FertigungsstraÃŸe, die Source-Code (HuggingFace, llama.cpp, Vosk) vollautomatisch in optimierte Binaries fÃ¼r dein Zielsystem verwandelt.

### ğŸš€ Was es kann (MVP):

* VollstÃ¤ndige Cross-Compilation fÃ¼r **Rockchip RK3566/RK3588** (inkl. NPU-Support via RKNN).
* Windows-Installer & GUI fÃ¼r einfache Bedienung.
* Zentrale "Single-Source-of-Truth" Architektur fÃ¼r Repositories.

### ğŸŒ Wo das Potential liegt (Und wo ich DICH brauche):
Die Architektur ist hardware-agnostisch. Das Framework ist so gebaut, dass es alles kompilieren kann â€“ von kleinen Edge-NPUs bis zu massiven Server-Farmen. Ich besitze nur Rockchip-Hardware, aber das Framework ist bereit fÃ¼r mehr:

* NVIDIA Jetson / Desktop GPUs?
* Intel NPUs / ARCs?
* RISC-V Boards?
* AMD ROCm?

### ğŸ¤ Der Aufruf:
Das GerÃ¼st steht. Die Logik ist solide. Jetzt braucht es die Community, um die Module fÃ¼r eure Hardware zu schreiben. Das System ist modular: Ein neues Target ist nur ein Ordner und ein Dockerfile entfernt.

**Lasst uns den Goldstandard fÃ¼r KI-Deployment bauen. Zusammen.**

ğŸ‘‰ **Fork it, build it, push it:** [GitHub Repository](https://github.com/Smilez1985/llm_conversion_framework)

> **âš ï¸ HINWEIS:** Dieses Projekt ist ein experimenteller Proof-of-Concept (Stand 20.11.2025) und wurde KI-gestÃ¼tzt entwickelt. Tests stehen noch aus.

> **âš ï¸ HINWEIS:**
> ### Installation von Docker Desktop (Wichtig!)
>
> Das Framework nutzt Docker Desktop mit WSL2 fÃ¼r alle Build-Prozesse. Dies ist eine **zwingende Voraussetzung** und kann nicht vom Framework selbst installiert werden.
>
> 1.  **Aktivieren Sie WSL2** (Windows Subsystem for Linux 2) Ã¼ber die PowerShell.
> 2.  Installieren Sie das [WSL2 Linux-Kernel-Update-Paket](https://wslstore.blob.core.windows.net/wslupdate/wsl_update_x64.msi).
> 3.  Laden Sie [Docker Desktop fÃ¼r Windows](https://docs.docker.com/desktop/install/windows-install/) herunter und installieren Sie es.
> 4.  Stellen Sie in den Docker-Einstellungen sicher, dass die **WSL2-Integration** aktiviert ist.
>
> Das Framework prÃ¼ft automatisch, ob Docker lÃ¤uft, bevor die Installation fortgesetzt wird.


---

## ğŸ¯ Features

- ğŸ—ï¸ **Multi-Architecture Support** - ARM, x86_64, RISC-V mit automatischer Hardware-Erkennung
- ğŸ³ **Docker-Native** - Isolierte Build-Umgebungen mit Multi-Stage Builds
- ğŸ¨ **Professional GUI** - PySide6 Interface mit 5-Schritt Module Creation Wizard
- âš¡ **Live Monitoring** - Real-time Build Output und Progress Tracking
- ğŸ”§ **Hardware-Optimized** - CPU-spezifische Compiler-Flags und SIMD-Optimierungen
- ğŸŒ **Community-Ready** - Plugin-System fÃ¼r neue Hardware-Targets
- ğŸ“¦ **Production Packaging** - Deployment-ready Output mit Test-Scripts
- ğŸ¤– **AI-Assisted** - Automatische Code-Generierung fÃ¼r neue Module

## ğŸš€ Quick Start

### Prerequisites

- **Docker** 20.10+ mit docker-compose
- **Python** 3.10+
- **Poetry** 1.5+ fÃ¼r Dependency Management
- **Git** fÃ¼r Repository-Verwaltung

### Installation

```bash
# 1. Repository klonen
git clone https://github.com/Smilez1985/llm_conversion_framework.git
cd llm_conversion_framework

# 2. Dependencies installieren
poetry install

# 3. Docker-Container bauen
docker-compose build

# 4. GUI starten
poetry run llm-builder
```

### Erste Schritte

1. **Hardware-Profil erstellen**  auf Ihrem Zielsystem:

```Bash
# Auf Ihrem RK3566/Zielsystem ausfÃ¼hren
curl -O https://raw.githubusercontent.com/Smilez1985/llm_conversion_framework/main/scripts/hardware_probe.sh
chmod +x hardware_probe.sh
./hardware_probe.sh
# Erzeugt: target_hardware_config.txt
```

2. **Modell konvertieren:**
``` Bash
# Via GUI: File â†’ Import Hardware Profile â†’ target_hardware_config.txt hochladen
# Build Configuration â†’ Modell wÃ¤hlen â†’ Target wÃ¤hlen â†’ Build starten

# Oder via CLI:
poetry run llm-cli build \
  --model models/granite-h-350m \
  --target rockchip \
  --quantization Q4_K_M \
  --hardware-profile configs/my_rk3566.txt
```

3. **Deployment:**

```Bash
# Output findet sich in output/packages/
cd output/packages/granite-h-350m_q4km_aarch64_latest/
./deploy.sh /opt/ai_models/
```

## ğŸ—ï¸ Architektur

### Framework-Struktur
```
llm-cross-compiler-framework/
â”œâ”€â”€ orchestrator/           # Framework Core (GUI + CLI)
â”œâ”€â”€ targets/                # Hardware-spezifische Module
â”‚   â”œâ”€â”€ rockchip/           # âœ… Radxa/Rockchip (RK3566, RK3588)
â”‚   â”œâ”€â”€ nvidia-jetson/      # ğŸš§ NVIDIA Jetson Familie
â”‚   â”œâ”€â”€ raspberry-pi/       # ğŸš§ Raspberry Pi Familie
â”‚   â””â”€â”€ _template/          # Template fÃ¼r neue Targets
â”œâ”€â”€ community/              # Community-contributed Targets
â”œâ”€â”€ docs/                   # Dokumentation
â””â”€â”€ scripts/                # Setup & Deployment Tools
```

### UnterstÃ¼tzte Hardware

| Familie | Status | Architekturen | Features |
|---------|--------|---------------|----------|
| **Rockchip** | âœ… Ready | RK3566, RK3568, RK3576, RK3588 | NEON, Cross-Compilation |
| **NVIDIA Jetson** | ğŸš§ Development | Nano, Xavier NX, Orin | CUDA, TensorRT |
| **Raspberry Pi** | ğŸš§ Development | Pi 4, Pi 5 | ARM Cortex-A72/A76 |
| **Intel NPU** | ğŸ“‹ Planned | Meteor Lake | OpenVINO |
| **Hailo** | ğŸ“‹ Planned | Hailo-8, Hailo-10 | HailoRT |


Jede Hardware-Familie implementiert 4 standardisierte Module:

```bash
1. source_module.sh    # Environment & Tools Setup
2. config_module.sh    # Hardware Detection & Flags
3. convert_module.sh   # Format Conversion (HFâ†’GGUF)
4. target_module.sh    # Quantization & Packaging
```

**Pipeline-Ablauf:**
```
Input Model â†’ Hardware Profile â†’ Docker Container â†’ Optimized Binary
     â†“              â†“                    â†“                  â†“
  HF/ONNX/PT   target_config.txt   Cross-Compilation   Deployment Package
```

## ğŸ› ï¸ Development

### Neues Hardware-Target hinzufÃ¼gen

Das Framework bietet einen **5-Schritt Module Creation Wizard**:

1. **Hardware Identification** - Name, Architektur, SDK, Boards
2. **Docker Environment** - Base OS, Packages, Setup Commands  
3. **Configuration Agent** - Compiler Flags, CMake Flags
4. **Profile Script** - Hardware Detection fÃ¼r Target-Systeme
5. **Summary & Generation** - AI-assisted Code Generation

```bash
# GUI-Wizard starten
poetry run llm-builder
# â†’ "New Module..." â†’ 5-Schritt-Wizard folgen

# Oder manuell:
cp -r targets/_template targets/my_hardware
# targets/my_hardware/ anpassen
```

### Module-Entwicklung Guidelines

**Goldstandard-Direktiven fÃ¼r alle Module:**

**Docker-Container:**
- âœ… Multi-Stage Build verwenden
- âœ… BuildX fÃ¼r Multi-Architektur
- âœ… Hadolint-konforme Syntax
- âœ… Poetry fÃ¼r Python-Dependencies

**Scripts (Shell/Python):**
- âœ… VollstÃ¤ndig funktionsfÃ¤hig (keine Platzhalter)
- âœ… Robuste `if not exist` Abfragen
- âœ… Professional dokumentiert/kommentiert
- âœ… Isolierte Umgebungen (Container-native)

### Testing

```bash
# Framework-Tests
poetry run pytest

# Target-Validation
./scripts/validate-target.sh targets/rockchip

# Integration-Test
poetry run llm-cli test --target rockchip --model test-model
```

## ğŸ“š Documentation

- ğŸ“– [Getting Started Guide](docs/getting-started.md)
- ğŸ”§ [Adding New Targets](docs/adding-targets.md)
- ğŸ“¡ [API Reference](docs/api-reference.md)
- ğŸ’¡ [Examples & Tutorials](docs/examples/)

## ğŸ¤ Community

### Beitragen

1. **Fork** das Repository
2. **Branch** erstellen: `git checkout -b feature/my-hardware-target`
3. **Module entwickeln** mit dem Module Creation Wizard
4. **Tests** hinzufÃ¼gen und ausfÃ¼hren
5. **Pull Request** erstellen

### Community-Targets

Die `community/` Directory enthÃ¤lt von der Community beigesteuerte Hardware-Targets:

- `community/hailo/` - Hailo NPU Support
- `community/intel-npu/` - Intel Meteor Lake NPU
- `community/custom-boards/` - Spezial-Hardware

### Support

- ğŸ› **Issues**: [GitHub Issues](https://github.com/Smilez1985/llm_conversion_framework/issues)
- ğŸ’¬ **Discussions**: [GitHub Discussions](https://github.com/Smilez1985/llm_conversion_framework/discussions)
- ğŸ“§ **Email**: -

## ğŸ“Š Status & Roadmap

### Current Status (v1.0.0)
- âœ… **Framework Core** - GUI, CLI, Docker-Management
- âœ… **Rockchip Target** - Production-ready fÃ¼r RK3566/3588
- âœ… **Module Creation Wizard** - Community-ready ??
- âœ… **Documentation** - Complete Getting Started

### Roadmap

**v1.1.0** (Q1 2026)
- ğŸ¯ NVIDIA Jetson Support (CUDA/TensorRT)
- ğŸ¯ Raspberry Pi Support
- ğŸ¯ Performance Benchmarking

**v1.2.0** (Q2 2026)
- ğŸ¯ Intel NPU Support (OpenVINO)
- ğŸ¯ Hailo NPU Support
- ğŸ¯ Auto-Optimization Engine

**v2.0.0** (Q3 2026)
- ğŸ¯ Cloud Build Support
- ğŸ¯ Model Zoo Integration
- ğŸ¯ Advanced Profiling Tools

## ğŸ† Examples

### Rockchip RK3566 Example

```bash
# Hardware-Profil erstellen (auf RK3566)
./hardware_probe.sh

# Build via CLI
poetry run llm-cli build \
  --model models/granite-h-350m \
  --target rockchip \
  --quantization Q4_K_M \
  --hardware-profile configs/rk3566_profile.txt

# Output: granite-h-350m_q4km_aarch64.zip
# EnthÃ¤lt: Quantisiertes Model + AArch64 Binary + Test Scripts
```

### Performance Expectations

| Model | Hardware | Quantization | RAM Usage | Speed (tokens/s) |
|-------|----------|-------------|-----------|------------------|
| Granite-350M | RK3566 | Q4_K_M | ~200MB | 8-15 |
| Llama-2-7B | RK3588 | Q4_K_M | ~4GB | 5-10 |
| Phi-2-2.7B | Pi 5 | Q5_K_M | ~2GB | 3-8 |

## ğŸ“„ License

MIT License - siehe [LICENSE](LICENSE) fÃ¼r Details.

## ğŸ™ Acknowledgments

- **llama.cpp** - Core quantization and inference engine
- **Hugging Face** - Model ecosystem and transformers
- **Docker** - Containerization platform
- **PySide6** - Professional GUI framework
- **Poetry** - Modern Python dependency management

---

**Built with â¤ï¸ for the AI Community**

*Empowering edge AI development through professional tooling and community collaboration.*
