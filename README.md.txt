# ğŸš€ LLM Cross-Compiler Framework

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![Docker](https://img.shields.io/badge/docker-20.10+-blue.svg)](https://docs.docker.com/get-docker/)
[![Poetry](https://img.shields.io/badge/poetry-1.5+-blue.svg)](https://python-poetry.org/)

**Professional modulares Framework fÃ¼r Cross-Compilation von Large Language Models auf Edge-Hardware**

Eliminiert die KomplexitÃ¤t der Cross-Kompilierung und Quantisierung von LLMs fÃ¼r fragmentierte Edge-Hardware (CPUs, GPUs, NPUs). Community-driven, Docker-basiert, production-ready.

## ğŸ¯ Features

- ğŸ—ï¸ **Multi-Architecture Support** - ARM, x86_64, RISC-V mit automatischer Hardware-Erkennung
- ğŸ³ **Docker-Native** - Isolierte Build-Umgebungen mit Multi-Stage Builds
- ğŸ¨ **Professional GUI** - PySide6 Interface mit 5-Schritt Module Creation Wizard
- âš¡ **Live Monitoring** - Real-time Build Output und Progress Tracking
- ğŸ”§ **Hardware-Optimized** - CPU-spezifische Compiler-Flags und SIMD-Optimierungen
- ğŸŒ **Community-Ready** - Plugin-System fÃ¼r neue Hardware-Targets
- ğŸ“¦ **Production Packaging** - Deployment-ready Output mit Test-Scripts
- ğŸ¤– **AI-Assisted** - Automatische Code-Generierung fÃ¼r neue Module

## ğŸš€ Quick Start

### Prerequisites

- **Docker** 20.10+ mit docker-compose
- **Python** 3.10+ 
- **Poetry** 1.5+ fÃ¼r Dependency Management
- **Git** fÃ¼r Repository-Verwaltung

### Installation

```bash
# 1. Repository klonen
git clone https://github.com/your-org/llm-cross-compiler-framework.git
cd llm-cross-compiler-framework

# 2. Dependencies installieren
poetry install

# 3. Docker-Container bauen
docker-compose build

# 4. GUI starten
poetry run llm-builder
```

### Erste Schritte

1. **Hardware-Profil erstellen** auf Ihrem Zielsystem:
   ```bash
   # Auf Ihrem RK3566/Zielsystem ausfÃ¼hren
   curl -O https://raw.githubusercontent.com/your-org/llm-cross-compiler-framework/main/scripts/hardware_probe.sh
   chmod +x hardware_probe.sh
   ./hardware_probe.sh
   # Erzeugt: target_hardware_config.txt
   ```

2. **Modell konvertieren**:
   ```bash
   # Via GUI: File â†’ Import Hardware Profile â†’ target_hardware_config.txt hochladen
   # Build Configuration â†’ Modell wÃ¤hlen â†’ Target wÃ¤hlen â†’ Build starten
   
   # Oder via CLI:
   poetry run llm-cli build \
     --model models/granite-h-350m \
     --target rockchip \
     --quantization Q4_K_M \
     --hardware-profile configs/my_rk3566.txt
   ```

3. **Deployment**:
   ```bash
   # Output findet sich in output/packages/
   cd output/packages/granite-h-350m_q4km_aarch64_latest/
   ./deploy.sh /opt/ai_models/
   ```

## ğŸ—ï¸ Architektur

### Framework-Struktur
```
llm-cross-compiler-framework/
â”œâ”€â”€ orchestrator/           # Framework Core (GUI + CLI)
â”œâ”€â”€ targets/                # Hardware-spezifische Module
â”‚   â”œâ”€â”€ rockchip/          # âœ… Radxa/Rockchip (RK3566, RK3588)
â”‚   â”œâ”€â”€ nvidia-jetson/     # ğŸš§ NVIDIA Jetson Familie  
â”‚   â”œâ”€â”€ raspberry-pi/      # ğŸš§ Raspberry Pi Familie
â”‚   â””â”€â”€ _template/         # Template fÃ¼r neue Targets
â”œâ”€â”€ community/             # Community-contributed Targets
â”œâ”€â”€ docs/                  # Dokumentation
â””â”€â”€ scripts/               # Setup & Deployment Tools
```

### UnterstÃ¼tzte Hardware

| Familie | Status | Architekturen | Features |
|---------|--------|---------------|----------|
| **Rockchip** | âœ… Ready | RK3566, RK3568, RK3576, RK3588 | NEON, Cross-Compilation |
| **NVIDIA Jetson** | ğŸš§ Development | Nano, Xavier NX, Orin | CUDA, TensorRT |
| **Raspberry Pi** | ğŸš§ Development | Pi 4, Pi 5 | ARM Cortex-A72/A76 |
| **Intel NPU** | ğŸ“‹ Planned | Meteor Lake | OpenVINO |
| **Hailo** | ğŸ“‹ Planned | Hailo-8, Hailo-10 | HailoRT |

### Workflow: 4-Module-Architektur

Jede Hardware-Familie implementiert 4 standardisierte Module:

```bash
1. source_module.sh    # Environment & Tools Setup
2. config_module.sh    # Hardware Detection & Flags
3. convert_module.sh   # Format Conversion (HFâ†’GGUF)
4. target_module.sh    # Quantization & Packaging
```

**Pipeline-Ablauf:**
```
Input Model â†’ Hardware Profile â†’ Docker Container â†’ Optimized Binary
     â†“              â†“                    â†“                  â†“
  HF/ONNX/PT   target_config.txt   Cross-Compilation   Deployment Package
```

## ğŸ› ï¸ Development

### Neues Hardware-Target hinzufÃ¼gen

Das Framework bietet einen **5-Schritt Module Creation Wizard**:

1. **Hardware Identification** - Name, Architektur, SDK, Boards
2. **Docker Environment** - Base OS, Packages, Setup Commands  
3. **Configuration Agent** - Compiler Flags, CMake Flags
4. **Profile Script** - Hardware Detection fÃ¼r Target-Systeme
5. **Summary & Generation** - AI-assisted Code Generation

```bash
# GUI-Wizard starten
poetry run llm-builder
# â†’ "New Module..." â†’ 5-Schritt-Wizard folgen

# Oder manuell:
cp -r targets/_template targets/my_hardware
# targets/my_hardware/ anpassen
```

### Module-Entwicklung Guidelines

**Goldstandard-Direktiven fÃ¼r alle Module:**

**Docker-Container:**
- âœ… Multi-Stage Build verwenden
- âœ… BuildX fÃ¼r Multi-Architektur
- âœ… Hadolint-konforme Syntax
- âœ… Poetry fÃ¼r Python-Dependencies

**Scripts (Shell/Python):**
- âœ… VollstÃ¤ndig funktionsfÃ¤hig (keine Platzhalter)
- âœ… Robuste `if not exist` Abfragen
- âœ… Professional dokumentiert/kommentiert
- âœ… Isolierte Umgebungen (Container-native)

### Testing

```bash
# Framework-Tests
poetry run pytest

# Target-Validation
./scripts/validate-target.sh targets/rockchip

# Integration-Test
poetry run llm-cli test --target rockchip --model test-model
```

## ğŸ“š Documentation

- ğŸ“– [Getting Started Guide](docs/getting-started.md)
- ğŸ”§ [Adding New Targets](docs/adding-targets.md)
- ğŸ“¡ [API Reference](docs/api-reference.md)
- ğŸ’¡ [Examples & Tutorials](docs/examples/)

## ğŸ¤ Community

### Beitragen

1. **Fork** das Repository
2. **Branch** erstellen: `git checkout -b feature/my-hardware-target`
3. **Module entwickeln** mit dem Module Creation Wizard
4. **Tests** hinzufÃ¼gen und ausfÃ¼hren
5. **Pull Request** erstellen

### Community-Targets

Die `community/` Directory enthÃ¤lt von der Community beigesteuerte Hardware-Targets:

- `community/hailo/` - Hailo NPU Support
- `community/intel-npu/` - Intel Meteor Lake NPU
- `community/custom-boards/` - Spezial-Hardware

### Support

- ğŸ› **Issues**: [GitHub Issues](https://github.com/your-org/llm-cross-compiler-framework/issues)
- ğŸ’¬ **Discussions**: [GitHub Discussions](https://github.com/your-org/llm-cross-compiler-framework/discussions)
- ğŸ“§ **Email**: llm-framework@example.com

## ğŸ“Š Status & Roadmap

### Current Status (v1.0.0)
- âœ… **Framework Core** - GUI, CLI, Docker-Management
- âœ… **Rockchip Target** - Production-ready fÃ¼r RK3566/3588
- âœ… **Module Creation Wizard** - Community-ready
- âœ… **Documentation** - Complete Getting Started

### Roadmap

**v1.1.0** (Q1 2024)
- ğŸ¯ NVIDIA Jetson Support (CUDA/TensorRT)
- ğŸ¯ Raspberry Pi Support
- ğŸ¯ Performance Benchmarking

**v1.2.0** (Q2 2024)
- ğŸ¯ Intel NPU Support (OpenVINO)
- ğŸ¯ Hailo NPU Support
- ğŸ¯ Auto-Optimization Engine

**v2.0.0** (Q3 2024)
- ğŸ¯ Cloud Build Support
- ğŸ¯ Model Zoo Integration
- ğŸ¯ Advanced Profiling Tools

## ğŸ† Examples

### Rockchip RK3566 Example

```bash
# Hardware-Profil erstellen (auf RK3566)
./hardware_probe.sh

# Build via CLI
poetry run llm-cli build \
  --model models/granite-h-350m \
  --target rockchip \
  --quantization Q4_K_M \
  --hardware-profile configs/rk3566_profile.txt

# Output: granite-h-350m_q4km_aarch64.zip
# EnthÃ¤lt: Quantisiertes Model + AArch64 Binary + Test Scripts
```

### Performance Expectations

| Model | Hardware | Quantization | RAM Usage | Speed (tokens/s) |
|-------|----------|-------------|-----------|------------------|
| Granite-350M | RK3566 | Q4_K_M | ~200MB | 8-15 |
| Llama-2-7B | RK3588 | Q4_K_M | ~4GB | 5-10 |
| Phi-2-2.7B | Pi 5 | Q5_K_M | ~2GB | 3-8 |

## ğŸ“„ License

MIT License - siehe [LICENSE](LICENSE) fÃ¼r Details.

## ğŸ™ Acknowledgments

- **llama.cpp** - Core quantization and inference engine
- **Hugging Face** - Model ecosystem and transformers
- **Docker** - Containerization platform
- **PySide6** - Professional GUI framework
- **Poetry** - Modern Python dependency management

---

**Built with â¤ï¸ for the AI Community**

*Empowering edge AI development through professional tooling and community collaboration.*