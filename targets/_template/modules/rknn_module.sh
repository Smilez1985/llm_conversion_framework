#!/bin/bash
# rknn_module.sh Template
# Generated by LLM Cross-Compiler Framework
# ZWECK: RKNN Conversion (ONNX -> RKNN)
# Nutzt die Python API von rknn-toolkit2 im Container.

set -euo pipefail

# Environment Variables injected by build.sh
# $MODEL_SOURCE
# $QUANTIZATION
# $OUTPUT_DIR

log() { echo ">> [RKNN] $1"; }
die() { echo "âŒ [RKNN] $1" >&2; exit 1; }

main() {
    log "Starting RKNN Pipeline..."
    
    if [[ "$MODEL_SOURCE" == "none" ]]; then
        log "No model source provided. Skipping."
        exit 0
    fi

    # Map Quantization
    case "${QUANTIZATION:-i8}" in
        "INT8"|"i8"|"Q8_0") Q_TYPE="i8";;
        "FP16") Q_TYPE="fp16";;
        *) Q_TYPE="i8"; log "Defaulting to i8";;
    esac

    # Output Path
    MODEL_NAME=$(basename "$MODEL_SOURCE" .onnx)
    RKNN_OUT="$OUTPUT_DIR/${MODEL_NAME}_${Q_TYPE}.rknn"

    log "Model: $MODEL_SOURCE"
    log "Quant: $Q_TYPE"
    log "Out:   $RKNN_OUT"

    # Create Python Conversion Script on the fly
    # This ensures we use the exact installed python libs in the container
    CONVERT_SCRIPT="$BUILD_CACHE_DIR/convert_rknn.py"
    
    cat <<EOF > "$CONVERT_SCRIPT"
import sys
from rknn.api import RKNN

rknn = RKNN(verbose=True)

# 1. Config
print("Configuring RKNN...")
# Target platform usually matches the board (rk3566, rk3588)
rknn.config(target_platform='rk3566') 

# 2. Load
print("Loading ONNX...")
ret = rknn.load_onnx(model='$MODEL_SOURCE')
if ret != 0:
    print("Load failed!")
    sys.exit(1)

# 3. Build
print("Building...")
ret = rknn.build(do_quantization=( '$Q_TYPE' == 'i8' ))
if ret != 0:
    print("Build failed!")
    sys.exit(1)

# 4. Export
print("Exporting to $RKNN_OUT...")
ret = rknn.export_rknn('$RKNN_OUT')
if ret != 0:
    print("Export failed!")
    sys.exit(1)
    
print("Success!")
EOF

    # Run
    python3 "$CONVERT_SCRIPT" || die "Python conversion failed"
    
    rm -f "$CONVERT_SCRIPT"
    log "RKNN Conversion Finished."
}

main "$@"
