# llm_conversion_framework [WARNING: The entire project was created with the help of AI (Claude/Gemini) and is, as of 2025-11-15, still untested!]
A GUI-based LLM Deployment Framework that: Can automatically optimize & quantize arbitrary LLMs. Perfectly optimized for any CPU, GPU, or NPU. MVP: RK3566 Support.

# ğŸš€ LLM Cross-Compiler Framework

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![Docker](https://img.shields.io/badge/docker-20.10+-blue.svg)](https://docs.docker.com/get-docker/)
[![Poetry](https://img.shields.io/badge/poetry-1.5+-blue.svg)](https://python-poetry.org/)

**Professional modular framework for cross-compilation of Large Language Models on edge hardware**

Eliminates the complexity of cross-compiling and quantizing LLMs for fragmented edge hardware (CPUs, GPUs, NPUs). Community-driven, Docker-based, production-ready.

## ğŸ¯ Features

- ğŸ—ï¸ **Multi-Architecture Support** - ARM, x86_64, RISC-V with automatic hardware detection
- ğŸ³ **Docker-Native** - Isolated build environments using multi-stage builds
- ğŸ¨ **Professional GUI** - PySide6 Interface with a 5-Step Module Creation Wizard
- âš¡ **Live Monitoring** - Real-time build output and progress tracking
- ğŸ”§ **Hardware-Optimized** - CPU-specific compiler flags and SIMD optimizations
- ğŸŒ **Community-Ready** - Plugin system for new hardware targets
- ğŸ“¦ **Production Packaging** - Deployment-ready output including test scripts
- ğŸ¤– **AI-Assisted** - Automatic code generation for new modules

## ğŸš€ Quick Start

### Prerequisites

- **Docker** 20.10+ with docker-compose
- **Python** 3.10+
- **Poetry** 1.5+ for dependency management
- **Git** for repository management



### Installation

```bash
# 1. Clone repository
git clone [https://github.com/Smilez1985/llm_conversion_framework.git]
cd llm_conversion_framework
```
```
# 2. Install dependencies
poetry install
```
```
# 3. Build Docker container
docker-compose build
```
```
# 4. Start GUI
poetry run llm-builder
```
### First Steps 

1. **Create Hardware Profile** on your target system:

```bash
# Run this on your RK3566/Target System
curl -O [https://github.com/Smilez1985/llm_conversion_framework/raw/main/scripts/hardware_probe.sh]
chmod +x hardware_probe.sh
./hardware_probe.sh
# Generates: target_hardware_config.txt
```
2. **Convert Model**:
```
# Via GUI: File â†’ Import Hardware Profile â†’ Upload target_hardware_config.txt
# Build Configuration â†’ Select Model â†’ Select Target â†’ Start Build


# Or via CLI:
poetry run llm-cli build \
  --model models/granite-h-350m \
  --target rockchip \
  --quantization Q4_K_M \
  --hardware-profile configs/my_rk3566.txt
```
3. **Deployment**:
```Bash
# Output is located in output/packages/
cd output/packages/granite-h-350m_q4km_aarch64_latest/
./deploy.sh /opt/ai_models/
```

## ğŸ—ï¸ Architecture
### Framework Structure
```
llm-cross-compiler-framework/
â”œâ”€â”€ orchestrator/           # Framework Core (GUI + CLI)
â”œâ”€â”€ targets/                # Hardware-specific modules
â”‚   â”œâ”€â”€ rockchip/           # âœ… Radxa/Rockchip (RK3566, RK3588)
â”‚   â”œâ”€â”€ nvidia-jetson/      # ğŸš§ NVIDIA Jetson Family
â”‚   â”œâ”€â”€ raspberry-pi/       # ğŸš§ Raspberry Pi Family
â”‚   â””â”€â”€ _template/          # Template for new targets
â”œâ”€â”€ community/              # Community-contributed targets
â”œâ”€â”€ docs/                   # Documentation
â””â”€â”€ scripts/                # Setup & Deployment Tools
```
### Supported Hardware

| Familie | Status | Architekturen | Features |
|---------|--------|---------------|----------|
| **Rockchip** | âœ… Ready | RK3566, RK3568, RK3576, RK3588 | NEON, Cross-Compilation |
| **NVIDIA Jetson** | ğŸš§ Development | Nano, Xavier NX, Orin | CUDA, TensorRT |
| **Raspberry Pi** | ğŸš§ Development | Pi 4, Pi 5 | ARM Cortex-A72/A76 |
| **Intel NPU** | ğŸ“‹ Planned | Meteor Lake | OpenVINO |
| **Hailo** | ğŸ“‹ Planned | Hailo-8, Hailo-10 | HailoRT |

### Workflow: 4-Module-Architektur

Each hardware family implements 4 standardized modules:

```bash
1. source_module.sh    # Environment & Tools Setup
2. config_module.sh    # Hardware Detection & Flags
3. convert_module.sh   # Format Conversion (HFâ†’GGUF)
4. target_module.sh    # Quantization & Packaging
```

Pipeline Flow:
```
Input Model â†’ Hardware Profile â†’ Docker Container â†’ Optimized Binary
     â†“              â†“                  â†“                   â†“
 HF/ONNX/PT   target_config.txt   Cross-Compilation   Deployment Package
```

## ğŸ› ï¸ Development: 

### Adding a New Hardware Target

The framework offers a **5-Step Module Creation Wizard**:

1. **Hardware Identification**  - Name, architecture, SDK, boards
2. **Docker Environment**- Base OS, packages, setup commands
3. **Configuration Agent** - Compiler flags, CMake flags
4. **Profile Script** - Hardware detection for target systems
5. **Summary & Generation** - AI-assisted code generation
   
```bash
Start GUI Wizard
poetry run llm-builder
# â†’ "New Module..." â†’ Follow the 5-step wizard


# Or manually:
cp -r targets/_template targets/my_hardware
# Customize targets/my_hardware/
```

### Module Development Guidelines:
**Gold Standard Directives for all modules:**

**Docker-Container:**
âœ… Use Multi-Stage Build
âœ… BuildX for Multi-Architecture support
âœ… Hadolint-compliant syntax
âœ… Poetry for Python dependencies

**Scripts (Shell/Python):**
âœ… Fully functional (no placeholders)
âœ… Robust if not exist checks
âœ… Professionally documented/commented
âœ… Isolated environments (container-native)

### Testing
```bash
Framework Tests
poetry run pytest

# Target Validation
./scripts/validate-target.sh targets/rockchip

# Integration Test
poetry run llm-cli test --target rockchip --model test-model
```

## ğŸ“š Documentation

- ğŸ“– [Getting Started Guide](docs/getting-started.md)
- ğŸ”§ [Adding New Targets](docs/adding-targets.md)
- ğŸ“¡ [API Reference](docs/api-reference.md)
- ğŸ’¡ [Examples & Tutorials](docs/examples/)

 
## ğŸ¤ Community

1. **Fork** the repository
2. **Create Branch**: git checkout -b feature/my-hardware-target
3. **Develop Module** using the Module Creation Wizard
4. Add & Run **Tests**
5. Create **Pull Request**

### Community-Targets

The `community/` directory contains hardware targets contributed by the community:

- `community/hailo/` - Hailo NPU Support
- `community/intel-npu/` - Intel Meteor Lake NPU
- `community/custom-boards/` - special-Hardware

### Support

ğŸ› Issues: GitHub Issues
ğŸ’¬ Discussions: GitHub Discussions
ğŸ“§ Email: -

## ğŸ“Š Status & Roadmap

### Current Status (v1.0.0)
âœ… **Framework Core** - GUI, CLI, Docker Management
âœ… **Rockchip Target** - Production-ready for RK3566/3588
âœ… **Module Creation Wizard** - Community-ready
âœ… **Documentation** - Complete Getting StartedRoadmapv1.1.0

### Roadmap

**v1.1.0** (Q1 2026)
- ğŸ¯ NVIDIA Jetson Support (CUDA/TensorRT)
- ğŸ¯ Raspberry Pi Support
- ğŸ¯ Performance Benchmarking

**v1.2.0** (Q2 2026)
- ğŸ¯ Intel NPU Support (OpenVINO)
- ğŸ¯ Hailo NPU Support
- ğŸ¯ Auto-Optimization Engine

**v2.0.0** (Q3 2026)
- ğŸ¯ Cloud Build Support
- ğŸ¯ Model Zoo Integration
- ğŸ¯ Advanced Profiling Tools

## ğŸ† Examples

### Rockchip RK3566 Example

```Bash
# Create hardware profile (on RK3566)
./hardware_probe.sh

# Build via CLI
poetry run llm-cli build \
  --model models/granite-h-350m \
  --target rockchip \
  --quantization Q4_K_M \
  --hardware-profile configs/rk3566_profile.txt

# Output: granite-h-350m_q4km_aarch64.zip
# Contains: Quantized Model + AArch64 Binary + Test Scripts
```

### Performance Expectations

| Model | Hardware | Quantization | RAM Usage | Speed (tokens/s) |
|-------|----------|-------------|-----------|------------------|
| Granite-350M | RK3566 | Q4_K_M | ~200MB | 8-15 |
| Llama-2-7B | RK3588 | Q4_K_M | ~4GB | 5-10 |
| Phi-2-2.7B | Pi 5 | Q5_K_M | ~2GB | 3-8 |

## ğŸ“„ License
MIT License - see [LICENSE](LICENSE) for details.


## ğŸ™ Acknowledgments

- **llama.cpp** - Core quantization and inference engine
- **Hugging Face** - Model ecosystem and transformers
- **Docker** - Containerization platform
- **PySide6** - Professional GUI framework
- **Poetry** - Modern Python dependency management

  
**Built with â¤ï¸ for the AI Community**

*Empowering edge AI development through professional tooling and community collaboration.*
