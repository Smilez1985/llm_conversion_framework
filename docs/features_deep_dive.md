# üìò Framework Deep Dive: Features & Architecture

> **Transparency Note:** This document explains the internal mechanics of the LLM Cross-Compiler Framework v1.5.0. We believe in "Glass Box" software ‚Äì you should always know exactly what your tools are doing.

---

## üß† 1. The "Ditto" AI Agent (Expert System)

### What is it?
Ditto is an automated embedded systems engineer. Instead of you spending hours searching for "Rockchip RK3588 CMake Flags AVX settings", Ditto analyzes your hardware and writes the configuration for you.

### ‚öôÔ∏è How it works (Internals)
1.  **Input:** Reads your `target_hardware_config.txt` (generated by the probe script).
2.  **Context Retrieval (v1.5.0):**
    * *Standard Mode:* Ditto checks if **Local RAG** is active.
    * *RAG Active:* It queries the local Qdrant database for SDK-specific documentation (e.g., "RKNN Toolkit2 quantization parameters").
    * *Fallback:* If RAG is off, it fetches the documentation URL defined in `project_sources.yml` (Single Source of Truth).
3.  **Generation:** It constructs a prompt for the LLM (OpenAI/Anthropic/Local) containing the hardware specs and the retrieved documentation context.
4.  **Output:** It generates a JSON object containing `cpu_flags`, `cmake_flags`, and `docker_base_image`.

### ‚ö†Ô∏è The Dangers (Transparent Risk Assessment)
* **Hallucination:** Like any LLM, Ditto can invent flags that don't exist.
    * *Mitigation:* v1.5.0 uses **Grounding**. By feeding Ditto the official SDK documentation via RAG, the hallucination rate is drastically reduced compared to "raw" GPT-4 usage.
* **Execution:** Ditto generates shell code for the `build.sh`.
    * *Mitigation:* The framework **never** executes Ditto's code blindly. You must review and confirm the generated module in the Wizard.

---

## üìö 2. Local Knowledge Base (RAG with Qdrant)

### What is it?
A private, local library of technical manuals. It turns the framework from a "tool" into a "knowledgeable partner".

### ‚öôÔ∏è How it works (The "Dynamic Sidecar")
We use a **Dynamic Sidecar Pattern** to keep the framework lightweight:
1.  **Idle:** By default, no database runs. Zero RAM usage.
2.  **Activation:** When you check "Enable Local Knowledge Base" in settings, the `DockerManager` pulls the official `qdrant/qdrant` image (~50MB).
3.  **Runtime:** The container `llm-qdrant` is started on a private Docker network. It is **never exposed** to the public internet.
4.  **Ingestion:** When you import documents (or sync from Community), text is chunked and converted into vectors (embeddings) locally using `litellm`.

### üõ°Ô∏è Privacy Guarantee
* **No Cloud Upload:** Your vector data resides in the Docker volume `llm_qdrant_data` on your machine.
* **No Telemetry:** We do not track what you index.

---

## ü§ù 3. Community Knowledge Sync ("The Brain")

### What is it?
A way to share "intelligence" without sharing secrets. Instead of everyone scraping the same NVIDIA manuals, one person does it and shares the "learned" vectors.

### ‚öôÔ∏è How it works
1.  **Export:** The `CommunityManager` uses the Qdrant Scroll API to read your vector database.
2.  **Sanitization (CRITICAL):** Before saving, a regex filter removes:
    * API Keys (`sk-...`, `hf_...`)
    * Local Paths (`C:\Users\John`, `/home/jenny`)
    * Internal IPs
3.  **Sharing:** The result is a JSON file saved to `community/knowledge/`. You can push this file to GitHub via Pull Request.
4.  **Import:** Other users pull the repo. Their framework sees the new JSON and ingests it into their local Qdrant instance.

---

## üéØ 4. Smart Calibration (Human-in-the-Loop)

### Why is it needed?
Aggressive quantization (like **INT8** or **W8A8** for NPUs) destroys model accuracy if not calibrated. Calibration requires a dataset (sentences) that matches the model's purpose (e.g., medical texts for a medical LLM).

### ‚öôÔ∏è How it works
1.  **Detection:** The `DatasetManager` detects if your chosen quantization requires calibration.
2.  **Missing Data?** If you provide no dataset, Ditto kicks in.
3.  **Generation:** Ditto generates synthetic sentences based on the model domain (e.g., "Write 50 Python coding prompts").
4.  **Verification:** The `DatasetReviewDialog` pops up. **You** see every single generated sentence. You can edit or delete them.
5.  **Injection:** Only after you click "Save", the data is written to `dataset.json` and mounted into the build container.

---

## üîí 5. Security Architecture

### Docker Socket Proxy
* **Risk:** Giving an application access to `/var/run/docker.sock` is usually equivalent to giving it root access.
* **Solution:** We use `tecnativa/docker-socket-proxy`. The framework talks to a proxy that **blocks** dangerous commands (like `docker system prune` or container breakouts) and only allows build-related API calls.

### Trivy Security Scanning
* **Risk:** Base images (like Ubuntu) often contain outdated packages with vulnerabilities (CVEs).
* **Solution:** Every time a build finishes, the `trivy-infra-scanner` container runs against your new image. It reports High/Critical vulnerabilities immediately in the build log.

### Secrets Management
* **Risk:** Storing API keys in plain text config files.
* **Solution:** The `SecretsManager` uses Python's `cryptography` library to encrypt API keys (OpenAI, HuggingFace) with a locally generated `master.key` (AES-256). Even if you accidentally share your config folder, your keys are unreadable without the key file.
