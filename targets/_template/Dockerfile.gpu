# Dockerfile.gpu - NVIDIA GPU Optimized Template
# LLM Cross-Compiler Framework
# DIREKTIVE: Goldstandard, CUDA-Support, Hadolint-konform

# ============================================================================
# STAGE 1: Build Environment (CUDA)
# ============================================================================
# Wir nutzen das offizielle NVIDIA Devel Image als Basis für Kompilierung
FROM nvidia/cuda:12.2.2-devel-ubuntu22.04 AS builder

LABEL maintainer="Community Contributor"
LABEL description="[Hardware-Familie] GPU Cross-Compilation Container"
LABEL target.sdk="CUDA"

ARG USER_ID=1000
ARG GROUP_ID=1000
ARG BUILD_JOBS=4
# Python Version in Ubuntu 22.04 ist 3.10, wir installieren 3.11 via ppa wenn nötig
# oder nutzen Standard. Hier nutzen wir Standard für Stabilität.

ENV DEBIAN_FRONTEND=noninteractive
ENV LLAMA_CPP_PATH=/usr/src/llama.cpp
ENV BUILD_CACHE_DIR=/build-cache
ENV PATH="/root/.local/bin:$PATH"
ENV CUDA_HOME=/usr/local/cuda

# System Dependencies
RUN apt-get update && \
    apt-get install -y --no-install-recommends \
        build-essential cmake make git curl wget ca-certificates \
        python3 python3-pip python3-dev python3-venv \
        pkg-config libffi-dev libssl-dev jq bc file time ccache \
        {packages_str} \
    && rm -rf /var/lib/apt/lists/* \
    && apt-get clean

# Python Environment (GPU Support)
# Wir installieren hier NICHT die CPU Version, sondern die volle CUDA Version
RUN python3 -m pip install --no-cache-dir --upgrade pip setuptools wheel
RUN python3 -m pip install --no-cache-dir \
        torch torchvision torchaudio \
        transformers tokenizers safetensors sentencepiece protobuf \
        huggingface-hub datasets numpy scipy onnx onnxruntime-gpu \
        tqdm psutil pyyaml requests

# ============================================================================
# STAGE 2: Runtime Environment (CUDA Runtime)
# ============================================================================
# Kleineres Runtime Image für die Ausführung
FROM nvidia/cuda:12.2.2-runtime-ubuntu22.04 AS runtime

LABEL stage="runtime"

ENV DEBIAN_FRONTEND=noninteractive
ENV BUILD_CACHE_DIR=/build-cache
ENV PATH="/app/modules:/app/scripts:${PATH}"
ENV NVIDIA_VISIBLE_DEVICES=all
ENV NVIDIA_DRIVER_CAPABILITIES=compute,utility

# Runtime Dependencies
RUN apt-get update && \
    apt-get install -y --no-install-recommends \
        python3 python3-pip cmake make git bc jq file curl \
    && rm -rf /var/lib/apt/lists/* && apt-get clean

# Copy Python Env from Builder
COPY --from=builder /usr/local/lib/python3.10/dist-packages /usr/local/lib/python3.10/dist-packages
COPY --from=builder /usr/local/bin /usr/local/bin

# Setup Directories & User
RUN groupadd -g ${GROUP_ID} llmbuilder && \
    useradd -u ${USER_ID} -g llmbuilder -d /app -s /bin/bash llmbuilder && \
    mkdir -p ${BUILD_CACHE_DIR}/{models,temp,output,logs,toolchains} && \
    chown -R llmbuilder:llmbuilder /app ${BUILD_CACHE_DIR}

WORKDIR /app
COPY modules/ ./modules/
COPY scripts/ ./scripts/
RUN chmod +x modules/*.sh scripts/*.sh

# Setup Entrypoint
COPY --chown=llmbuilder:llmbuilder docker/entrypoint.sh /entrypoint.sh
RUN chmod +x /entrypoint.sh

WORKDIR ${BUILD_CACHE_DIR}
USER llmbuilder

VOLUME ["${BUILD_CACHE_DIR}"]

ENTRYPOINT ["/entrypoint.sh"]
CMD ["interactive"]
