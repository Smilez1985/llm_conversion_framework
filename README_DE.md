# ğŸš€ LLM Cross-Compiler Framework
**DITTO: Definitive Inference Target Translation On-Edge**


[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![Docker](https://img.shields.io/badge/docker-20.10+-blue.svg)](https://docs.docker.com/get-docker/)
[![Status](https://img.shields.io/badge/Status-Production%20Ready-green.svg)]()
[![Version](https://img.shields.io/badge/version-2.0.0-blue.svg)]()
[![GitHub Stars](https://img.shields.io/github/stars/Smilez1985/llm_conversion_framework?style=social)](https://github.com/Smilez1985/llm_conversion_framework)
[![GitHub Forks](https://img.shields.io/github/forks/Smilez1985/llm_conversion_framework?style=social)](https://github.com/Smilez1985/llm_conversion_framework)

> **Hinweis:** FÃ¼r die englische Dokumentation siehe [README.md](README.md).

**Die autonome MLOps-Plattform fÃ¼r Edge-AI.**  
Ein selbstverwaltendes, selbstheilendes Framework, das Large Language Models (LLMs) fÃ¼r jede Hardware (Rockchip, NVIDIA, Intel, etc.) kompiliert, optimiert und deployt â€“ ohne "Dependency-HÃ¶lle".

---

## ğŸŒŸ Was ist neu in v2.0.0 (The Brain Update)

Wir haben das Framework von einem "Werkzeug" in ein **Intelligentes System** verwandelt.

* ğŸ§  **Native Offline-Intelligenz:** Ditto lÃ¤uft jetzt lokal (TinyLlama/Qwen) ohne Internet oder externe Docker-Container. Null AbhÃ¤ngigkeiten.
* ğŸš‘ **Selbstheilende Architektur:** Builds schlagen nicht einfach fehl; sie diagnostizieren sich selbst. Das Framework erkennt Treiber-Konflikte oder fehlende Bibliotheken und schlÃ¤gt exakte Reparatur-Befehle vor.
* ğŸ›¡ï¸ **Guardian Layers (Schutzschichten):**
    * **Konsistenz-Gate:** Verhindert zum Scheitern verurteilte Builds, indem es SDK- und Treiber-KompatibilitÃ¤t *vor* der AusfÃ¼hrung prÃ¼ft.
    * **Wissens-Versicherung:** Automatische RAG-Snapshots ermÃ¶glichen Rollbacks, falls die KI falsche Informationen lernt.
    * **Ethik-Gate:** Warnt vor dem Download bei Modellen mit restriktiven Lizenzen.
* ğŸ”® **Selbstbewusstsein:** Ditto indiziert nun seinen eigenen Quellcode (`/app`), wodurch er tiefe architektonische Fragen zum Framework selbst beantworten kann.

[VollstÃ¤ndigen Changelog ansehen](CHANGELOG.md) | [Upgrade Guide](docs/upgrade_v2.0.md)

---

## âš¡ Hauptfunktionen

### ğŸ—ï¸ Multi-Architektur Support
Kompilieren Sie Modelle fÃ¼r jede Zielarchitektur von einem einzigen x86-Host aus. UnterstÃ¼tzt **Rockchip NPU** (RKNN), **NVIDIA GPU** (TensorRT), **Intel XPU** (IPEX/OpenVINO) und mehr.

### ğŸ¤– Autonomer KI-Agent (Ditto)
Ditto ist nicht mehr nur ein Wizard.
* **Deep Ingest:** Crawlt Dokumentations-Webseiten und PDFs, um neue SDKs zu erlernen.
* **Chat-Interface:** Stellen Sie Fragen wie *"Warum ist mein Build fehlgeschlagen?"* oder *"Wie optimiere ich fÃ¼r 8GB RAM?"*.
* **GedÃ¤chtnis:** Erinnert sich an Ihren Hardware-Kontext, hÃ¤lt den Chat aber durch "Rolling Context Compression" sauber.

### ğŸš€ Zero-Dependency Deployment
Schieben Sie Ihre optimierten Modelle mit einem Klick auf das Edge-GerÃ¤t.
* **Sicher:** Zugangsdaten existieren nur im RAM.
* **Robust:** "Network Guard" pausiert den Transfer bei Verbindungsabbruch.
* **Einfach:** Generiert ein eigenstÃ¤ndiges `deploy.sh` auf dem ZielgerÃ¤t.

### ğŸ›¡ï¸ Security-First Architektur
* **Socket Proxy:** Isoliert Docker, um Root-AusbrÃ¼che zu verhindern.
* **Trivy Scanning:** PrÃ¼ft jedes Build-Image auf CVEs (SicherheitslÃ¼cken).
* **Sanitization:** Telemetrie (Opt-In) entfernt automatisch API-Keys und Benutzerpfade.

---

## ğŸ“‚ Projektstruktur
```
.
â”œâ”€â”€ Launch-LLM-Conversion-Framework.bat # One-Click Installer & Launcher
â”œâ”€â”€ assets/                             # UI Ressourcen (Ditto Avatare)
â”œâ”€â”€ orchestrator/
â”‚   â”œâ”€â”€ gui/                            # PySide6 GUI (Chat, Wizard, Monitoring)
â”‚   â”œâ”€â”€ Core/                           # Das Gehirn
â”‚   â”‚   â”œâ”€â”€ self_healing_manager.py     # Auto-Diagnose
â”‚   â”‚   â”œâ”€â”€ consistency_manager.py      # Pre-Flight Checks
â”‚   â”‚   â”œâ”€â”€ ditto_manager.py            # Native Inferenz
â”‚   â”‚   â””â”€â”€ rag_manager.py              # Wissensbasis & Snapshots
â”œâ”€â”€ targets/                            # Hardware Module (Rockchip, Intel, etc.)
â”œâ”€â”€ community/
â”‚   â””â”€â”€ knowledge/                      # Geteilte RAG Snapshots
â””â”€â”€ output/                             # Golden Artifacts
```

---

## ğŸ“Ÿ UnterstÃ¼tzte Hardware

| Familie | Status | Chips | Features |
|---------|--------|-------|----------|
| **Rockchip** | âœ… Production | RK3588, RK3566, RK3576 | RKLLM, RKNN, W8A8 |
| **NVIDIA** | âœ… Production | Orin, Xavier, RTX 30/40 | TensorRT, CUDA 12 |
| **Intel** | âœ… Production | Arc A-Series, Core Ultra | IPEX-LLM, OpenVINO |
| **Raspberry Pi** | ğŸš§ Beta | Pi 5 + Hailo-8L | HailoRT, PCIe |
| **RISC-V** | ğŸŒ Community | VisionFive 2 | Vector Ext. (V) |

---

## ğŸ“¥ Installation & Nutzung

### Windows (One-Click)

1. Laden Sie das Repository herunter.
2. Doppelklicken Sie auf **Launch-LLM-Conversion-Framework.bat**.
3. Installiert automatisch Python/Git falls fehlend, richtet die Umgebung ein und aktualisiert sich selbst.

### Linux (Headless / CI)
```bash
make setup  # PrÃ¼ft Gruppen & Rechte
make up     # Startet Orchestrator
docker exec -it llm-orchestrator llm-cli
```

---

## ğŸ› ï¸ Der Workflow

1. **Probe:** FÃ¼hren Sie `./hardware_probe.sh` auf Ihrem ZielgerÃ¤t aus.
2. **Import:** Laden Sie das Profil in der GUI.
3. **Konsultieren:** Fragen Sie Ditto: *"Ist dieses Modell mit meinen 8GB RAM kompatibel?"*
4. **Bauen:** WÃ¤hlen Sie Modell & Format (GGUF/RKNN). Das Konsistenz-Gate sichert die KompatibilitÃ¤t.
5. **Deployen:** Klicken Sie auf "Deploy to Target", um das Golden Artifact via SSH zu Ã¼bertragen.

---

## ğŸ¤ Community & Governance

- **Wissen teilen:** Exportieren Sie Ihre RAG-Snapshots nach `community/knowledge/`, um anderen zu helfen.
- **Telemetrie:** Opt-In anonyme Berichterstattung hilft uns, Bugs schneller zu beheben. (Wir tracken niemals Prompts oder private Keys).
- **Support:** Ã–ffnen Sie eine [GitHub Discussion](https://github.com/Smilez1985/llm_conversion_framework/discussions).

---

## ğŸ“„ Lizenz

Lizenziert unter der **MIT License**. Siehe [LICENSE](LICENSE) fÃ¼r Details.

---

<div align="center">

[â­ Star us on GitHub](https://github.com/Smilez1985/llm_conversion_framework) | [ğŸ“– Dokumentation](#) | [ğŸ’¬ Discord](#)

**Empowering developers to run AI everywhere.**

</div>
