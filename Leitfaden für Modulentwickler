Leitfaden f√ºr Modulentwickler

Architektur des LLM Deployment Frameworks

Willkommen in der Community! Dieses Framework wurde entwickelt, um die Komplexit√§t der Cross-Kompilierung und Quantisierung von Large Language Models (LLMs) f√ºr fragmentierte Edge-Hardware (CPUs, GPUs, NPUs) zu eliminieren.
Das gesamte System basiert auf einem Modul-Template-System. Jede unterst√ºtzte Hardware-Familie (z.B. Radxa Rockchip, NVIDIA Jetson, Hailo-8) lebt in einem eigenen, isolierten Ordner und definiert ihre eigene Build-Umgebung.
Ziel: Ihre Aufgabe als Drittentwickler ist es, einen neuen Ordner (targets/[IHRE_ARCHITEKTUR]) zu erstellen, der die vier kritischen Template-Dateien enth√§lt.

I. Die Vier Module: Der Goldstandard-Satz
Jeder Architektur-Ordner muss diese vier Dateien enthalten. Die Logik des Systems wird von diesen Shell-Skripten im Docker-Container gesteuert.
Datei-Name	Zweck	Zust√§ndigkeit	Anzupassen?
Dockerfile	Definiert die Build-Umgebung (Basis-OS, Cross-Compiler, SDKs).	Baut das Docker-Image f√ºr die Architekturgruppe (z.B. alle AArch64-CPUs).	Ja (Nur bei neuen Compilern/SDKs).
source_module.sh	Download & FP16 GGUF Konvertierung.	L√§dt das Modell und konvertiert es in das Basisformat (FP16 GGUF).	Nein (Bleibt generell statisch).
config_module.sh	HARDWARE-AGENT (Das Herzst√ºck).	Liest die Ziel-Hardware-Konfiguration und generiert die spezifischen Optimierungs-Flags (z.B. mcpu=, CUDA-Pfade, HailoRT-Config).	Ja (Kernanpassung).
target_module.sh	Quantisierung & Kompilierung.	Orchestriert den gesamten Prozess, ruft Quantize auf und f√ºhrt die Cross-Kompilierung mit den von config_module.sh gesetzten Flags durch.	Nein (Bleibt generell statisch).

II. Schritt-f√ºr-Schritt: Neues Modul hinzuf√ºgen
Als Entwickler konzentrieren Sie sich haupts√§chlich auf config_module.sh und das Dockerfile.

Schritt 1: Das Dockerfile erstellen (Dockerfile)
Erstellen Sie ein Dockerfile, das alle notwendigen Compiler, Toolchains und propriet√§ren SDKs f√ºr Ihre Hardware-Familie bereitstellt.

Beispiele f√ºr kritische Schritte:

1.	Radxa Rockchip/AArch64: Installation von crossbuild-essential-arm64.
2.	NVIDIA Jetson: Installation des CUDA Toolkits und der entsprechenden Header-Dateien (oft in einem Multi-Stage Build).
3.	Hailo-8: Installation des HailoRT SDK und der spezifischen Python-Wheels.

Schritt 2: Den Konfigurations-Agenten schreiben (config_module.sh)
Dieses Skript ist der wichtigste Teil. Es muss die hardware-spezifischen Optimierungen in eine von target_module.sh lesbare Form bringen.

1.	Lese Input: Lesen Sie die hochgeladene target_hardware_config.txt (die die CPU-Kerne, Taktraten, NPU-Version usw. enth√§lt).

2.	Setze Flags:
o	F√ºr CPUs: Generieren Sie ein [IHRE_ARCH].cmake Toolchain-File. Darin setzen Sie CMAKE_C_FLAGS und CMAKE_CXX_FLAGS mit den -mcpu= und mfpu= Optimierungen f√ºr die Ziel-CPU.
o	F√ºr GPUs/NPUs: Erstellen Sie Umgebungsvariablen oder Konfigurationsdateien, die die nachfolgende Kompilierung in target_module.sh dazu anweisen, die entsprechenden Bibliotheken zu verlinken 
(z.B. -DGGML_CUDA=ON oder -DGGML_HAILO=ON im CMake-Aufruf).

Schritt 2.A: Data Acquisition: Das Zielsystem-Profil

Das Framework ben√∂tigt pr√§zise Hardware-Details (CPU-Kerne, Cache-Gr√∂√üen, NPU-Versionen), um optimale Compiler-Flags zu setzen. Diese Informationen werden in der Datei target_hardware_config.txt √ºbermittelt.
Herkunft und Integration der Datei:

‚Ä¢	Erstellung des Profils: Die Datei muss auf dem Zielsystem (der Edge-Hardware) generiert werden. Modulentwickler m√ºssen ein separates Pre-Configuration Script (z.B. ein einfaches Bash- oder Python-Skript) 
bereitstellen, das System-Metadaten ausliest (z.B. /proc/cpuinfo, lscpu, Versionsnummern von SDKs) und diese standardisiert in die target_hardware_config.txt schreibt.
‚Ä¢	Upload √ºber GUI: Die Hauptanwendung muss eine Upload-Funktion bereitstellen, √ºber die der Benutzer die auf seinem Zielsystem erstellte target_hardware_config.txt hochladen kann. 
Diese Datei wird dann in den Docker-Cache-Mountpoint (/build-cache) gelegt, damit der config_module.sh darauf zugreifen und die Optimierungen ableiten kann.

Schritt 3: Den target_module.sh anpassen (Falls n√∂tig)
Das Standard-target_module.sh (siehe Canvas) funktioniert f√ºr die meisten CPU-Kompilierungen.

Anpassung erforderlich bei:

‚Ä¢	GPU/NPU-Backend: Wenn Ihre Hardware ein spezielles llama.cpp-Backend (wie CUDA oder OpenVINO) ben√∂tigt, m√ºssen Sie den cmake Befehl in SCHRITT 4 um die entsprechenden DCMAKE_... Flags erweitern.
o	Beispiel (CUDA): F√ºgen Sie -DGGML_CUDA=ON und -DCUBLAS=ON zum cmake-Aufruf hinzu.

Schritt 4: Testen und Dokumentieren
Bevor Sie Ihr Modul teilen, testen Sie den Build-Prozess mit einer bekannten Modellkonfiguration. Erstellen Sie eine README.md in Ihrem Modul-Ordner, die beschreibt, welche spezifischen SDK-Lizenzen 
oder Hardware-Voraussetzungen f√ºr den Build erforderlich sind.

III. KI-gest√ºtzte Entwicklung (Prompt-Beispiel)
Da dieses Framework die Automatisierung f√∂rdert, k√∂nnen Sie Large Language Models (LLMs) verwenden, um die initialen Skripte zu erstellen.

üìù Der Muster-Prompt f√ºr eine KI

Kopieren Sie diesen Prompt und ersetzen Sie die Platzhalter ([HARDWARE NAME], [ARCHITEKTUR], [SDK-NAME]) durch Ihre spezifischen Werte.

Ich entwickle ein Open-Source LLM Deployment Framework, das Module f√ºr verschiedene Hardware-Architekturen verwendet.

Das Framework basiert auf Docker und Shell-Skripten. Meine Ziel-Hardware-Familie ist: [HARDWARE NAME] (z.B. AMD Ryzen 7 7740U).

Die Ziel-Architektur ist: [ARCHITEKTUR] (z.B. x86_64).
Das zu verwendende Spezial-SDK ist: [SDK-NAME] (z.B. OpenVINO 2023.2).

Aufgabenstellung:
1. Erstelle ein **Dockerfile** f√ºr Debian, das die [ARCHITEKTUR] Cross-Toolchain und das [SDK-NAME] (oder ggf. nur x86_64-Build-Essentials) installiert.
2. Erstelle das **config_module.sh** Skript. Dieses Skript soll eine simulierte oder reale Datei namens 'target_hardware_config.txt' aus dem Mount-Punkt "/build-cache" lesen.
3. Im **config_module.sh** soll ein **CMake-Toolchain-File** oder eine **spezifische Konfigurationsdatei** generiert werden, die die Compiler-Optimierungs-Flags setzt. 
F√ºr [HARDWARE NAME] sind die wichtigsten Optimierungen: [LISTE WICHTIGER COMPILER-FLAGS, z.B. AVX512 und OpenMP, oder die korrekten CUDA-Pfade].
4. Erstelle die **target_module.sh** so, dass sie nach dem Aufruf von config_module.sh, die Cross-Kompilierung von llama.cpp unter Verwendung dieser generierten Flags startet. 
Nutze den Befehl 'cmake' mit der Option '-DCMAKE_TOOLCHAIN_FILE' und der Option '-DGGML_[IHRE OPTIMIERUNG]=ON'.

Halte die Skripte sauber, gut kommentiert und verwende Bash-Standardfunktionen.

üóÇÔ∏è Wichtiger Hinweis zur Hardware-Konfiguration
Die notwendigen technischen Details (z.B. der korrekte Wert f√ºr -mcpu=... oder die Versionsnummer der NPU) k√∂nnen nicht immer von der KI erraten werden.

Empfehlung: Entwickeln Sie ein kleines Helfer-Skript, das auf der Ziel-Hardware (z.B. dem Jetson-Ger√§t) ausgef√ºhrt wird und die genauen Kernel-Versionen, CUDA-Pfade oder CPU-Namen ausliest 
und diese Daten in die target_hardware_config.txt schreibt. Diese Datei kann dann hochgeladen und von Ihrem config_module.sh im Container ausgelesen werden.

IV. Der Modul-Erstellungs-Wizard (Interaktiver Leitfaden)
DER WIZZARD EXISTIERT NOCH NICHT, IST NUR GEPLANT, MUSS NOCH ENTWICKELT WERDEN...
Die GUI dient als Assistent (Wizard), der auch wenig versierte Entwickler oder Power-User durch die Erstellung eines neuen Moduls f√ºhrt, indem er die Komplexit√§t in kleine, handhabbare Schritte zerlegt.

Wizard-Flow: Neues Modul erstellen

Schritt	Ziel der GUI-Eingabe	Ausgabe/Aktion (f√ºr den Entwickler)

1. Hardware-Identifikation	Name des Moduls: NVIDIA Jetson Ziel-Architektur: AArch64 Spezial-SDK/Backend: CUDA	Erstellt den Ordner targets/nvidia_jetson/ und f√ºllt statische Vorlagen 
(source_module.sh, target_module.sh) auf Basis des Backends.
2. Docker-Umgebung	Basis-Betriebssystem: Debian 12 Ben√∂tigte Pakete: cuda-toolkit-12.2, python3-pip Zus√§tzliche Shell-Befehle: <Code-Block f√ºr SDK-Installation>	Generiert das Dockerfile in targets/nvidia_jetson/,
indem es die eingegebenen Pakete und Befehle in die Basisvorlage einf√ºgt.
3. Konfigurations-Agent	Wichtigste Compiler-Flags: -mcpu=cortex-a76, -DGGML_CUDA=ON Logik f√ºr target_hardware_config.txt: Lies Wert X aus Zeile Y und setze Flag Z	Generiert das config_module.sh. 
Hier wird der KI-Prompt aus Abschnitt III genutzt: Die GUI fragt die KI mit den gesammelten Daten, um den ersten Entwurf des Skripts zu erstellen.
4. Profil-Skript-Vorschlag	Ziel-Plattform: Linux/ARM Befehle zur Datenextraktion: lscpu -p und nvcc --version	Generiert ein vorgefertigtes Bash-Skript (generate_config.sh), das der Entwickler auf 
dem Zielsystem ausf√ºhren kann, um die target_hardware_config.txt zu erstellen.
5. Zusammenfassung & Verfeinerung	Wizard zeigt alle 4 generierten Dateien in einem Editor an.	Aufforderung: "Bitte √ºberpr√ºfen und bearbeiten Sie die Dateien, insbesondere das config_module.sh, 
um propriet√§re Pfade und Optimierungen zu finalisieren."

Durch diesen Wizard wird selbst ein unerfahrener Benutzer in der Lage sein, die vier notwendigen Dateien zu generieren, ohne tiefgreifende Kenntnisse in Docker oder Cross-Kompilierung zu haben. 
Es ist die perfekte Br√ºcke zwischen der technischen Komplexit√§t und der Community-Einfachheit.

