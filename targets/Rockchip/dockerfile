# Dockerfile for Rockchip RK3588/RK3566
# Generated by LLM Cross-Compiler Framework
# Target Architecture: aarch64

FROM debian:bookworm-slim AS builder

LABEL maintainer="Community Contributor"
LABEL description="Target for NVIDIA Jetson Orin" 
# (Hinweis: Description wird vom Generator gesetzt, hier exemplarisch f√ºr Rockchip)# Dockerfile for Rockchip RK3588/RK3566
# Generated by LLM Cross-Compiler Framework
# Target Architecture: aarch64
# DIREKTIVE: Goldstandard, Verified Sources, Zero-Config.

# ============================================================================
# STAGE 1: Build Environment
# ============================================================================
FROM debian:bookworm-slim AS builder

LABEL maintainer="LLM Framework Team"
LABEL description="Rockchip RK3588/RK3566 Cross-Compilation Container"
LABEL target.architecture="aarch64"

# CI Build Args
ARG USER_ID=1000
ARG GROUP_ID=1000

ENV DEBIAN_FRONTEND=noninteractive
ENV LLAMA_CPP_PATH=/usr/src/llama.cpp
ENV BUILD_CACHE_DIR=/build-cache
ENV PATH="/root/.local/bin:$PATH"

# 1. System Dependencies
# 'git-lfs' hinzugef√ºgt f√ºr Robustheit bei Large Files in Repos
RUN apt-get update && apt-get install -y --no-install-recommends \
        build-essential cmake git git-lfs python3-pip \
        python3-dev python3-venv pkg-config libffi-dev libssl-dev \
        wget curl \
    && rm -rf /var/lib/apt/lists/*

# 2. Python Environment Setup
RUN python3 -m pip install --no-cache-dir --upgrade pip setuptools wheel

# Install CPU-only PyTorch (Platzsparend f√ºr den Builder, NPU nutzt rknn)
RUN python3 -m pip install --no-cache-dir \
        torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu

# Install Framework Dependencies
RUN python3 -m pip install --no-cache-dir \
        transformers tokenizers safetensors sentencepiece protobuf \
        huggingface-hub datasets numpy scipy onnx onnxruntime \
        tqdm psutil pyyaml requests

# ============================================================================
# OFFICIAL SDK INJECTION (Verified)
# ============================================================================
WORKDIR /tmp

# 3. RKLLM-Toolkit (LLM Quantisierung)
# QUELLE: https://github.com/airockchip/rknn-llm/tree/release-v1.2.1b1
# Wir nutzen den spezifischen Branch, der die Wheels enth√§lt.
RUN echo "‚¨áÔ∏è Cloning RKLLM Toolkit (release-v1.2.1b1)..." && \
    git clone -b release-v1.2.1b1 --depth 1 https://github.com/airockchip/rknn-llm.git && \
    echo "üì¶ Installing RKLLM Wheel..." && \
    pip3 install --no-cache-dir rknn-llm/rkllm-toolkit/packages/rkllm_toolkit-*-cp311-cp311-linux_x86_64.whl && \
    rm -rf rknn-llm

# 4. RKNN-Toolkit2 (Vision/Audio Quantisierung)
# QUELLE: https://github.com/airockchip/rknn-toolkit2
RUN echo "‚¨áÔ∏è Cloning RKNN Toolkit2..." && \
    git clone -b v2.0.0-beta0 --depth 1 https://github.com/airockchip/rknn-toolkit2.git && \
    echo "üì¶ Installing RKNN Wheel..." && \
    pip3 install --no-cache-dir rknn-toolkit2/rknn-toolkit2/packages/rknn_toolkit2-*-cp311-cp311-linux_x86_64.whl && \
    rm -rf rknn-toolkit2

# 5. Verification (Smoke Test)
# Bricht den Build ab, wenn die Module nicht importierbar sind.
RUN python3 -c "from rkllm.api import RKLLM; print('‚úÖ RKLLM Module verified')"
RUN python3 -c "from rknn.api import RKNN; print('‚úÖ RKNN Module verified')"

# ============================================================================
# STAGE 2: Runtime Setup
# ============================================================================

WORKDIR /app

# Copy framework modules (Context-Aware Build Copy)
# Durch den Patch im builder.py liegen die Dateien im Build-Context root
COPY modules/ ./modules/
COPY scripts/ ./scripts/
RUN chmod +x modules/*.sh scripts/*.py

# Set working directory & User
WORKDIR ${BUILD_CACHE_DIR}

# Create User mapping host UID/GID
RUN groupadd -g ${GROUP_ID} llmbuilder && \
    useradd -u ${USER_ID} -g llmbuilder -d /app -s /bin/bash llmbuilder && \
    chown -R llmbuilder:llmbuilder /app

# Default entrypoint
COPY docker/entrypoint.sh /entrypoint.sh
RUN chmod +x /entrypoint.sh

USER llmbuilder
ENTRYPOINT ["/entrypoint.sh"]
CMD ["interactive"]
LABEL target.architecture="aarch64"

# CI Args
ARG USER_ID=1000
ARG GROUP_ID=1000

ENV DEBIAN_FRONTEND=noninteractive
ENV LLAMA_CPP_PATH=/usr/src/llama.cpp
ENV BUILD_CACHE_DIR=/build-cache

# System dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
        build-essential cmake git python3-pip \
    && rm -rf /var/lib/apt/lists/*

# Copy framework modules
WORKDIR /app
COPY modules/ ./modules/
COPY scripts/ ./scripts/
RUN chmod +x modules/*.sh scripts/*.py

# Set working directory & User
WORKDIR ${BUILD_CACHE_DIR}

# Create User mapping host UID/GID
RUN groupadd -g ${GROUP_ID} llmbuilder && \
    useradd -u ${USER_ID} -g llmbuilder -d /app -s /bin/bash llmbuilder && \
    chown -R llmbuilder:llmbuilder /app

# Default entrypoint
COPY docker/entrypoint.sh /entrypoint.sh
RUN chmod +x /entrypoint.sh

USER llmbuilder
ENTRYPOINT ["/entrypoint.sh"]
CMD ["interactive"]
