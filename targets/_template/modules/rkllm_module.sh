#!/bin/bash
# rkllm_module.sh Template
# Generated by LLM Cross-Compiler Framework
#
# ZWECK: Wrapper für RKLLM-Toolkit (LLM Quantisierung auf RK3588/RK3576).
# Nutzt 'export_rkllm.py' für die eigentliche Arbeit.

set -euo pipefail

# ============================================================================
# ENVIRONMENT
# ============================================================================

MODEL_SOURCE="${MODEL_SOURCE:-}"
QUANTIZATION="${QUANTIZATION:-w8a8}"
BUILD_CACHE_DIR="${BUILD_CACHE_DIR:-/build-cache}"
OUTPUT_DIR="${OUTPUT_DIR:-${BUILD_CACHE_DIR}/output}"
SCRIPT_DIR="/app/scripts"
RKLLM_DIR="/app/rknn-llm"

# Logging
log_info() { echo ">> [RKLLM-Module] $(date '+%H:%M:%S') INFO: $1"; }
log_error() { echo ">> [RKLLM-Module] $(date '+%H:%M:%S') ERROR: $1" >&2; }
die() { log_error "$1"; exit 1; }

# ============================================================================
# MAIN LOGIC
# ============================================================================

main() {
    log_info "Initializing RKLLM Pipeline..."

    # 1. Validierung
    if [[ -z "$MODEL_SOURCE" ]]; then
        die "Environment variable MODEL_SOURCE is not set."
    fi
    
    if [[ ! -d "$MODEL_SOURCE" ]]; then
        die "Model Source '$MODEL_SOURCE' does not exist or is not a directory (HuggingFace format required)."
    fi

    # 2. Quantisierung Mapping
    case "${QUANTIZATION}" in
        "w8a8"|"W8A8"|"INT8"|"Q8_0")
            Q_TYPE="w8a8"
            ;;
        "w4a16"|"W4A16"|"INT4"|"Q4_K_M")
            Q_TYPE="w4a16"
            ;;
        *)
            log_info "Unknown quantization '$QUANTIZATION'. Defaulting to 'w8a8'."
            Q_TYPE="w8a8"
            ;;
    esac

    # 3. Target Platform (RKLLM supports rk3588, rk3576)
    TARGET_PLATFORM="rk3588" # Default
    if [[ "${TARGET_BOARD:-}" == *"3576"* ]]; then
        TARGET_PLATFORM="rk3576"
    fi

    # 4. Toolkit Setup (Self-Healing)
    if [ ! -d "$RKLLM_DIR" ]; then
        log_info "RKLLM Toolkit not found at $RKLLM_DIR. Attempting clone..."
        # URL from Environment (injected by SSOT) or Default
        REPO_URL="${RKLLM_TOOLKIT_REPO_OVERRIDE:-https://github.com/airockchip/rknn-llm.git}"
        git clone "$REPO_URL" "$RKLLM_DIR" || die "Failed to clone RKLLM Toolkit."
    fi

    # 5. Python Script Call
    CONVERTER="$SCRIPT_DIR/export_rkllm.py"
    
    if [ ! -f "$CONVERTER" ]; then
        die "Converter script missing at $CONVERTER."
    fi
    
    MODEL_NAME=$(basename "$MODEL_SOURCE")
    OUTPUT_FILE="$OUTPUT_DIR/${MODEL_NAME}_${TARGET_PLATFORM}_${Q_TYPE}.rkllm"
    
    log_info "Starting Conversion: $MODEL_NAME -> $Q_TYPE on $TARGET_PLATFORM"
    
    set +e
    python3 "$CONVERTER" \
        --model "$MODEL_SOURCE" \
        --output "$OUTPUT_FILE" \
        --quant "$Q_TYPE" \
        --target "$TARGET_PLATFORM"
    
    EXIT_CODE=$?
    set -e
    
    if [ $EXIT_CODE -eq 0 ] && [ -f "$OUTPUT_FILE" ]; then
        log_info "✅ Success! RKLLM Artifact: $OUTPUT_FILE"
    else
        die "Conversion failed (Exit Code: $EXIT_CODE) or Output missing."
    fi
}

main "$@"
